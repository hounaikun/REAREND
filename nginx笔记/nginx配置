1.nginx是什么：是一个高性能的HTTP和反向代理服务器。
2.nginx特点：占有内存少，并发能力强
3.反向代理：
	3.1正向代理：浏览器中配置代理服务器，通过代理服务器去访问目标服务器（已知目标服务器地址，需要在浏览器中配置）
	3.2反向代理：客户端对代理是无感的，我们只需要将请求发送到反向代理服务器，由反向代理服务器去选择目标服务器获取数据后，再返回客户端，
					此时反向代理服务器和目标服务器对外就是一个服务器，暴露的是代理服务器地址，隐藏了真实服务器ip地址。（不知道数据源头是哪个服务器，由反	向代理服务器选择）
4.负载均衡：
	单个服务器解决不了，我们增加服务器的数量，然后将请求分发到各个服务器上，将原先请求集中到单个服务器上的情况改为将请求分发到多个服务器上，将负载分发到不同的服务器，也就是我们说的负载均衡。
5.动静分离
	为了加快网站的解析速度，可以把动态页面和静态页面由不同的服务器来解析，加快解析速度。降低原来单个服务器的压力。
6.linux系统中安装
	6.1 nginx相关的依赖（先安装3个依赖）			
			zlib
				
			openssl

				使用 yum -y install make zlib zlib-devel gcc-c++ libtool openssl openssl-devel 完成对上两个依赖的下载和安装

			pcre-8.37 
				下载：wget https://ftp.pcre.org/pub/pcre/pcre-8.37.tar.gz
				解压：tar -zxvf pcre-8.37.tar.gz
				进入解压目录，执行./configure
				执行 make && make install ，编译并安装(需要已经安装了gcc-c++)
				查看安装的版本：pcre-config --version

	6.2 安装nginx
			下载：wget http://nginx.org/download/nginx-1.12.2.tar.gz
			解压：tar -zxvf nginx-1.12.2.tar.gz
				进入解压目录，执行./configure
				执行 make && make install ，编译并安装
			安装目录：/usr/local/nginx
			启动脚本：/usr/local/nginx/sbin

	6.3 设置防火墙（如果不设置，外部访问不了;其中云服务器要配置安全组，放开80端口）
			防火墙启动：systemctl start firewalld
			防火墙停止：systemctl disable firewalld
			查看开放的端口号：firewall-cmd --list-all
			设置开放的端口：sudo firewall-cmd --add-port=80/tcp --permanent
			防火墙重启：firewall-cmd --reload

7.nginx常用命令
	7.1 首先进入到/usr/local/nginx/sbin
	7.2 查看nginx版本号
		./nginx -v
	7.3 启动nginx
		./nginx
	7.4 关闭nginx
		./nginx -s stop
	7.5 重新加在nginx
		./nginx -s reload

8.nginx的配置文件
	位置：/usr/local/nginx/conf/nginx.conf
	组成：nginx配置文件由三部分组成
	8.1 全局块
		从配置文件开始到events块之间的内容，主要会设置一些影响nginx服务器整体运行的配置指令
		比如：worker_processes  1;  worker_processes值越大，可以支持的并发处理量也越多
	8.2 events块
		events块涉及的指令主要影响Nginx服务器与用户的网络连接
		比如 worker_connections  1024;支持的最大连接数
	8.3 http块
		nginx 配置最频繁的部分
		http块也可以包括http全局块、server块

9.反向代理配置
	9.1 实现效果
		使用nginx反向代理，根据访问的路径跳转到不同的端口的服务中，nginx监听端口是9001，
			访问 http://ip:9001/edu/ 直接跳转到127.0.0.1:8081（tomcat）
			访问 http://ip:9001/vod/ 直接跳转到127.0.0.1:8082（tomcat）
	9.2 在windows系统的host文件进行域名和ip对应关系的配置
		C:\Windows\System32\drivers\etc\hosts 中配置
	9.3 修改配置文件
		server {
	        listen       80;  #监听的端口号
	        server_name  localhost; #监听的ip

	        #当浏览器输入上面的ip+端口的话就会执行下面location，可以写多个location和server
			location ~ .*\.fcgi$ {
				root cgi-bin;
					fastcgi_pass localhost:2000;
					fastcgi_index index.cgi;
					include fastcgi.conf;					
			}
		}
	9.4 location写法
		地址：https://www.cnblogs.com/phonecom/p/7216706.html
			本地地址：file:///D:/%E6%89%8B%E5%8A%A8%E5%AD%98%E7%9A%84%E7%BD%91%E9%A1%B5/nginx%E9%85%8D%E7%BD%AElocation.html
10.负载均衡
	10.1 实现效果
		浏览器输入http://ip/edu/a.html,负载均衡效果，平均分配到8080和8081端口中去
	10.2 修改配置文件
		upstream myserver{
			server ip:8080;
			server ip:8081;
		}
		server {
			listen       80;  #监听的端口号
	        server_name  ip; #监听的ip

	        #当浏览器输入上面的ip+端口的话就会执行下面location，可以写多个location和server
			location / {
				proxy_pass http://myserver;				
			}
		}
	10.3 分配服务器策略
		第一种：轮询（默认）
			每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。
		第二种：权重
			weight 代表权重，默认是1，权重越高被分配的客户端越多
			upstream myserver{
				server ip:8080 weight = 5;
				server ip:8081 weight = 10;
			}
		第三种：ip_hash
			每个请求按访问ip的hash结果分配，这样每个访客（同一个ip）固定访问一个后端服务器，可以解决session问题
			upstream myserver{
				ip_hash;
				server ip:8080;
				server ip:8081;
			}
		第四种：fair
			按后端服务器的响应时间来分配请求，响应时间短的优先分配。
			upstream myserver{
				server ip:8080;
				server ip:8081;
				fair;
			}

11.动静分离
	11.1 概念
		不能理解成只是单纯的把动态页面和静态页面物理分开，应该是动态请求和静态请求分开，可以理解成使用Nginx处理静态页面，Tomcat处理动态页面；
		通过 location指定不同的后缀名实现不同的请求转发。通过 expires参数设置,可以览器缓存过期时间,减少与服务器之前的请求和流量。具体Expires定义:
			是给一个资源设定一个过期时间,也就是说无需去服务端验证,直接通过浏览器自身确认是否过期即可，所以不会产生额外的流量。此种方法非常适合不经常变动的资源。(如果经常更新的文件不建议使用 Expires来缓存),我这里设置3d,表示在这3天之内访问这个URL,发送个请求,比对服务器该文件最后更新时间没有变化,则不会从服务器抓取,返回状态码304，如果有修改,则直接从服务器重新下载,返回状态码200

12.高可用
	12.1 概念
		主nginx宕机了，自动切换到备nginx
	12.2 准备工作
		- 需要两台服务器
		- 在两台服务器安装nginx
		- 在两台服务器安装keepalived(keepalived可以检测哪台nginx宕机了)
			安装命令：yum install keepalived -y
			安装目录：/etc/keepalived
			配置文件位置：安装目录/keepalived.conf
	12.3 进行配置
		- 修改/etc/keepalived/keepalived.conf配置文件
			#全局定义块，以下模版不能省略
			global_defs {
			   #如有故障，发邮件的地址。
			   notification_email {
			     acassen@firewall.loc
			     failover@firewall.loc
			     sysadmin@firewall.loc
			   }
			   notification_email_from Alexandre.Cassen@firewall.loc
			   smtp_server 192.168.200.1
			    
			   #邮件服务链接超时的最长时间
			   smtp_connect_timeout 30
			   #访问到服务器主机的名字（在vi /etc/hosts中添加127.0.0.1 LVS_DEVEL）
			   router_id LVS_DEVEL
			}
			#VRRP实例定义块
			vrrp_instance VI_1 {
			    state MASTER #状态只有MASTER和BACKUP两种，并且要大写，MASTER为工作状态，BACKUP是备用状态。
			    interface eth0 #网卡名称
			        lvs_sync_daemon_inteface eth0  #这个默认没有，相当于心跳线接口，DR模式用的和上面的接口一样，也可以用机器上的其他网卡eth1，用来防止脑裂。
			    virtual_router_id 51 #虚拟路由标识，同一个vrrp_instance的MASTER和BACKUP的vitrual_router_id 是一致的。
			    priority 100  #优先级，同一个vrrp_instance的MASTER优先级必须比BACKUP高。
			    advert_int 1 #MASTER 与BACKUP 负载均衡器之间同步检查的时间间隔，单位为秒。
			    authentication {
			        auth_type PASS  #验证authentication。包含验证类型和验证密码。类型主要有PASS、AH 两种，通常使用的类型为PASS，\
			        auth_pass 1111  据说AH 使用时有问题。验证密码为明文，同一vrrp 实例MASTER 与BACKUP 使用相同的密码才能正常通信。
			    }
			    virtual_ipaddress { #虚拟ip地址,可以有多个地址，每个地址占一行，不需要子网掩码，同时这个ip 必须与我们在lvs 客户端设定的vip 相一致！
			        192.168.200.100
			        192.168.200.101
			        192.168.200.102
			    }
			}
			#虚拟服务器定义块
			virtual_server 192.168.200.100 443 {  #虚拟IP，来源与上面的虚拟IP地址，后面加空格加端口号
			    delay_loop 6  #健康检查间隔，单位为秒
			    lb_algo rr    #负载均衡调度算法，一般用wrr、rr、wlc
			    lb_kind NAT  #负载均衡转发规则。一般包括DR,NAT,TUN 3种。
			    persistence_timeout 50 #会话保持时间，会话保持，就是把用户请求转发给同一个服务器，不然刚在1上提交完帐号密码，就跳转到另一台服务器2上了。
			    protocol TCP  #转发协议，有TCP和UDP两种，一般用TCP，没用过UDP。

			    real_server 192.168.201.100 80 { #真实服务器，包括IP和端口号
			        weight 1  #权重，数值越大，权重越高
			        TCP_CHECK {  #通过tcpcheck判断RealServer的健康状态
			            connect_timeout 3 #连接超时时间
			            nb_get_retry 3 #重连次数
			            delay_before_retry 3 #重连时间间隔
			            connect_port 80  #检测端口
			        }
			    }
			}
			其实配置文件中主要要修改的选项没有很多，有三个参数要注意
			route_id  XXX #MASTER和BACKUP不同
			virtual_router_id 51 #同一个实例下，MASTER和BACKUP相同
			priority 100 #优先级，同一个实例下，MASTER高于BACKUP

		- 启动nginx；启动keepalived：systemctl start keepalived.service

13.原理
	13.1 master和worker
			- 启动nginx后，其中有两个进程master和worker（其中有一个master，但可以有多个worker）
			- client请求到master，master把请求分给worker（worker通过争抢的方式获得请求）
	13.2 一个master和多个worker有什么好处
			- 可以使用nginx -s reload 热部署
			- 每个worker是独立的进程，如果其中一个worker出现问题，其他worker是独立的，继续进行争抢，实现请求过程，不会造成服务中断
	13.3 设置到少个worker合适
			- 一般worker数和服务器的cpu相等最适宜
	13.4 连接数worker_connection
			- 发送请求，占用了worker的几个连接数？ 2（nginx直接返回响应）个或者4（nginx请求其他服务器，比如Tomcat服务器）个
			- nginx有一个master，有四个worker，每个worker支持的最大连接数1024，支持的最大并发数是多少？ 
				普通的静态访问最大并发数：worker_connection*worker_process/2
				是作为Http反向代理来说最大并发数：worker_connection*worker_process/2



